# Open MPI基础

## 前言

* MPI(Message Passing Interface)是一种标准或规范的代表，而不指对它的具体实现。
* MPI是一种**消息传递**的编程模型，即解决的是并行程序中的通信问题，MPI现在成为编程模型的代表和事实上的标准。
* MPI是接口，因此需要对它进行实现。MPI的实现是库，而非语言。Open MPI仅为MPI的一种实现。
* 本章介绍的API均出自`mpi.h`。完整可见[官方文档v4.0](https://www.open-mpi.org/doc/v4.0/)

## 6.3.1 基本概念

* 通信器(Communicator): 完成进程间通信的基本环境，用于**指定通信的范围**。
* 序号(rank): 进程的唯一标识符。
* 消息(message): 在进程之间传递的数据。由`通信器`、`源地址`、`目标地址`、`消息标签`、`数据`组成。
* MPI程序运行时，会自动创建两个通信器：MPI_COMM_WORLD 与 MPI_COMM_SELF。

```CPP
/* Communicators */
typedef int MPI_Comm; // 基本的通信器类型。

#define MPI_COMM_WORLD ((MPI_Comm)0x44000000) // 包含MPI程序中的所有进程
#define MPI_COMM_SELF  ((MPI_Comm)0x44000001) // 单个进程自己所构成的通信器


/* Datatypes */
typedef int MPI_Datatype;

#define MPI_CHAR           ((MPI_Datatype)0x4c000101)
#define MPI_SIGNED_CHAR    ((MPI_Datatype)0x4c000118)
#define MPI_UNSIGNED_CHAR  ((MPI_Datatype)0x4c000102)
#define MPI_BYTE           ((MPI_Datatype)0x4c00010d)
#define MPI_WCHAR          ((MPI_Datatype)0x4c00040e)
#define MPI_SHORT          ((MPI_Datatype)0x4c000203)
#define MPI_UNSIGNED_SHORT ((MPI_Datatype)0x4c000204)
#define MPI_INT            ((MPI_Datatype)0x4c000405)
#define MPI_UNSIGNED       ((MPI_Datatype)0x4c000406)
#define MPI_LONG           ((MPI_Datatype)0x4c000807)
#define MPI_UNSIGNED_LONG  ((MPI_Datatype)0x4c000808)
#define MPI_FLOAT          ((MPI_Datatype)0x4c00040a)
#define MPI_DOUBLE         ((MPI_Datatype)0x4c00080b)
#define MPI_LONG_DOUBLE    ((MPI_Datatype)0x4c00100c)
#define MPI_LONG_LONG_INT  ((MPI_Datatype)0x4c000809)
#define MPI_UNSIGNED_LONG_LONG ((MPI_Datatype)0x4c000819)
#define MPI_LONG_LONG      MPI_LONG_LONG_INT


/* Collective operations */
typedef int MPI_Op;

#define MPI_MAX     (MPI_Op)(0x58000001)
#define MPI_MIN     (MPI_Op)(0x58000002)
#define MPI_SUM     (MPI_Op)(0x58000003)
#define MPI_PROD    (MPI_Op)(0x58000004)
#define MPI_LAND    (MPI_Op)(0x58000005)
#define MPI_BAND    (MPI_Op)(0x58000006)
#define MPI_LOR     (MPI_Op)(0x58000007)
#define MPI_BOR     (MPI_Op)(0x58000008)
#define MPI_LXOR    (MPI_Op)(0x58000009)
#define MPI_BXOR    (MPI_Op)(0x5800000a)
#define MPI_MINLOC  (MPI_Op)(0x5800000b)
#define MPI_MAXLOC  (MPI_Op)(0x5800000c)
#define MPI_REPLACE (MPI_Op)(0x5800000d)
#define MPI_NO_OP   (MPI_Op)(0x5800000e)
```

## 6.3.1 MPI_Init

* [MPI_Init](https://www.open-mpi.org/doc/v4.0/man3/MPI_Init.3.php)初始化MPI且仅初始化一次。
* Open MPI 接受 命令行 的 C/C++ argc 和 argv 传参，但对它们不做任何操作。
* 尽量避免在初始化(即MPI_Init)**之前**做一些改变程序外部的事情，比如打开文件或操作iostream。

```CPP
int MPI_Init(int *argc, char ***argv);
```

## 6.3.2 MPI_Finalize

* [MPI_Finalize](https://www.open-mpi.org/doc/v4.0/man3/MPI_Finalize.3.php)清除MPI状态。
* 当最后一个进程调用该API时，所有挂起的发送必须与一个接受相匹配，所有挂起的接受必须与一个发送相匹配。
* 尽量避免在初始化(即MPI_Init)**之后**做一些改变程序外部的事情，比如打开文件或操作iostream。

```CPP
int MPI_Finalize();

/*
一个MPI程序的布局：
    // 1. 声明一些变量;
    // 2. MPI_Init(*argc, &argv);
    // 3. 做一些改变程序外部的事情，比如打开文件或操作iostream。
    // 4. 完成一些功能
    // 5. MPI_Finalize();
*/
```

## 6.3.3 MPI_Comm_size

* [MPI_Comm_size](https://www.open-mpi.org/doc/v4.0/man3/MPI_Comm_size.3.php)指示通信器涉及的进程数。
* 进程个数size被该API做出了修改，就确定了当前通信器（communicator）的组（group）。
* 通常与 `MPI_Comm_rank` 一起使用，以确定可用的并发量。

```CPP
int MPI_Comm_size(MPI_Comm comm, int *size);
/*
    Args:
        comm(MPI_Comm): 一个通信器。可以传入MPI自动创建的两个通信器：MPI_COMM_WORLD 或 MPI_COMM_SELF。
        size(int *): 进程数的地址。
    Example:
        int num_procs;
        MPI_Init(*argc, &argv); // 必须先初始化
        MPI_Comm_size(MPI_COMM_WORLD, &num_procs); // num_procs将被确定
*/

```

## 6.3.3 MPI_Comm_rank

* [MPI_Comm_rank](https://www.open-mpi.org/doc/v4.0/man3/MPI_Comm_rank.3.php)确定了当前通信器中所有进程各自唯一对应的标识符rank。
* 在调用`MPI_Comm_size`后，进程数量就被确定为`int *size`所指向的值。因此rank的范围为[0, size - 1];
* 在调用`MPI_Comm_rank`后，当前进程的唯一rank就明确了（从所确定的rank范围中选取）。

```CPP
int MPI_Comm_rank(MPI_Comm comm, int *rank);
/*
    Args:
        comm(MPI_Comm): 一个通信器。可以传入MPI自动创建的两个通信器：MPI_COMM_WORLD 或 MPI_COMM_SELF。
        size(int *): 进程数的地址。
    Example:
        int num_procs, current_rank;
        MPI_Init(&argc, &argv);

        MPI_Comm_size(MPI_COMM_WORLD, &num_procs);
        MPI_Comm_rank(MPI_COMM_WORLD, &current_rank);
*/
```

## 6.3.4 MPI_Bcast

[MPI_Bcast](https://www.open-mpi.org/doc/v4.0/man3/MPI_Bcast.3.php)从一个能看到rank root的进程，将消息**广播**到所有其他进程。

```CPP
int MPI_Bcast(void *buffer, 
              int count, 
              MPI_Datatype datatype,
              int root, 
              MPI_Comm comm)
/*
    Args:
        buffer(void *): 通信缓存区的首地址。
        count(int): 通信缓存区中的条目数(entries)。
        datatype(MPI_Datatype): 从通信缓存区发送的数据类型。
        root(int): 广播源的rank序号（即唯一标识符）。
        comm(MPI_Comm): 一个通信器。可以传入MPI自动创建的两个通信器：MPI_COMM_WORLD 或 MPI_COMM_SELF。

    Example:
        double Matrix_size = 10; // 矩阵尺寸
        double Matrix[Matrix_size][Matrix_size]; // 矩阵

        MPI_Bcast(&Matrix_size, 1, MPI_DOUBLE, 0, MPI_COMM_WORLD); //将矩阵的大小广播给所有进程

        for (int i = 0; i < Matrix_size; i++) // 将整个矩阵广播给所有进程
            MPI_Bcast(Matrix[i], Matrix_size, MPI_DOUBLE, 0, MPI_COMM_WORLD); // 缓存区共有10条数据。

*/

```

## 6.3.5 MPI_Reduce

* [MPI_Reduce](https://www.open-mpi.org/doc/v4.0/man3/MPI_Reduce.3.php)执行规约操作。
* 通信器指定的是通信范围，也就是一个组（group）。规约就是将这个组中所有进程的输入缓冲区(sendbuf)作为输入，经过op的操作（可以使用预定义的op，也可以自定义），最后将规约后的结果放到输出缓冲区(recvbuf)中。
* 可以对应到PCAM设计方法学的第三阶段：组合。

```CPP
int MPI_Reduce( const void *sendbuf, 
                void *recvbuf, 
                int count,
                MPI_Datatype datatype, 
                MPI_Op op, 
                int root,
                MPI_Comm comm)

/*
    Args:
        sendbuf(const void *) : 指针，指向发送消息的内存块。
        recvbuf(void *) : 指针，指向接受消息的内存块。
        count(int): 数据量。
        datatype(MPI_Datatype) : 数据类型。
        op(MPI_Op) : 要执行何种规约操作
        root(int) : root进程的rank序号（即唯一标识符）。
        comm(MPI_Comm): 一个通信器。可以传入MPI自动创建的两个通信器：MPI_COMM_WORLD 或 MPI_COMM_SELF。 

    Example:
        double per_procs = 0.0; // 每个进程的运行结果
        double result = 0.0; // 最终的运行结果，是由每个进程运行结果经op定义的处理后，组合得到的。

        // 即result = result + per_procs。MPI_SUM表示使用的是加法。
        MPI_Reduce(&per_procs, &result, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD); 
*/
```
